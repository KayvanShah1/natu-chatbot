{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing dependencies"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ipython-autotime\n%load_ext autotime\n%matplotlib inline","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting ipython-autotime\n  Downloading ipython-autotime-0.1.tar.bz2 (1.2 kB)\nBuilding wheels for collected packages: ipython-autotime\n  Building wheel for ipython-autotime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ipython-autotime: filename=ipython_autotime-0.1-py3-none-any.whl size=1830 sha256=31a42bb9856f3c866dbecdb39b2e27da1ec2594f3d50c43f7fee9db589fa0ee5\n  Stored in directory: /root/.cache/pip/wheels/65/56/4a/4b967e4b9b62bd9d8d7ca789bba648c702d705487f28845bb2\nSuccessfully built ipython-autotime\nInstalling collected packages: ipython-autotime\nSuccessfully installed ipython-autotime-0.1\n\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport nltk \nimport numpy as np\nimport re, unicodedata\nfrom nltk.stem import wordnet \nfrom sklearn.feature_extraction.text import TfidfVectorizer \nfrom nltk import pos_tag \nfrom sklearn.metrics import pairwise_distances \nfrom nltk import word_tokenize \nfrom nltk.corpus import stopwords \nfrom tqdm.notebook import tqdm\nimport random","execution_count":2,"outputs":[{"output_type":"stream","text":"time: 1.4 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Reading Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_path = '/kaggle/input/cloud-counselage-qa-data/'\n\ndata = pd.read_excel(data_path + 'faq_data.xlsx')\ndata.ffill(axis = 0,inplace=True)\ndata.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                            question  \\\n0       I am not able to access my Bitrix24 account?   \n1  What is the job profile? Will we be able to wo...   \n2  How many workgroups will an intern be a part of?    \n3                How many workgroups should I be in?   \n4      Not able to access the LP1 page with my token   \n\n                                       response_text  \n0  Go to https://cloudcounselage24.bitrix24.com/ ...  \n1  Your job profile is 'Technology - Intern'; if ...  \n2  Every intern should be a part of 2 workgroups....  \n3  Every intern should be a part of 2 workgroups....  \n4  Please watch the videos shared with the invite...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>response_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am not able to access my Bitrix24 account?</td>\n      <td>Go to https://cloudcounselage24.bitrix24.com/ ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the job profile? Will we be able to wo...</td>\n      <td>Your job profile is 'Technology - Intern'; if ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How many workgroups will an intern be a part of?</td>\n      <td>Every intern should be a part of 2 workgroups....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many workgroups should I be in?</td>\n      <td>Every intern should be a part of 2 workgroups....</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Not able to access the LP1 page with my token</td>\n      <td>Please watch the videos shared with the invite...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"time: 408 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stopword list\npattern = re.compile(r'\\b('+r'|'.join(stopwords.words('english'))+r')\\b\\s*')\n\n# @cuda.jit(device=True)\ndef unicode_to_ascii(s):\n  return ''.join(c for c in unicodedata.normalize('NFD', s)\n      if unicodedata.category(c) != 'Mn')\n\n# @tf.function()\ndef clean_text(text):\n    text = unicode_to_ascii(str(text).lower().strip())\n    \n    # creating a space between a word and the punctuation following it\n    text = re.sub(r\"([?.!,¿])\", r\" \\1 \", text)\n    text = re.sub(r'[\" \"]+', \" \", text)\n    \n    # replacing all the stopwords\n    text = pattern.sub('',text)\n    \n    # removes all the punctuations\n    text = re.sub(r\"[^a-zA-Z]+\", \" \", text)\n    \n    text = text.strip()\n    \n    # adding a start and an end token to the sentence so that the model know when to start and stop predicting.\n#     text = '<start> ' + text + ' <end>'\n    \n    return text\n\nclean_text_vect = np.vectorize(clean_text)","execution_count":4,"outputs":[{"output_type":"stream","text":"time: 13.8 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def chunk_clean(array,chunk_size=256):\n    cleaned_array = []\n    \n    for i in tqdm(range(0, len(array), chunk_size)):\n        text_chunk = clean_text_vect(array[i:i+chunk_size])\n        cleaned_array.extend(text_chunk)\n\n    return np.array(cleaned_array)","execution_count":5,"outputs":[{"output_type":"stream","text":"time: 1.11 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lema=wordnet.WordNetLemmatizer()\n\ndef text_normalization(text): \n    tokens=nltk.word_tokenize(text)     \n    tags_list=pos_tag(tokens,tagset=None) \n\n    lema_words=[] \n    for token,pos_token in tags_list:\n        if pos_token.startswith('V'):  # Verb\n            pos_val='v'\n        elif pos_token.startswith('J'): # Adjective\n            pos_val='a'\n        elif pos_token.startswith('R'): # Adverb\n            pos_val='r'\n        else:\n            pos_val='n' # Noun\n            \n        lema_token=lema.lemmatize(token,pos_val) \n        lema_words.append(lema_token) \n    \n    return \" \".join(lema_words)\n\ntext_norm_vect = np.vectorize(text_normalization)","execution_count":6,"outputs":[{"output_type":"stream","text":"time: 3.54 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def chunk_text_normalize(array,chunk_size=256):\n    norm_array = []\n    \n    for i in tqdm(range(0, len(array), chunk_size)):\n        text_chunk = text_norm_vect(array[i:i+chunk_size])\n        norm_array.extend(text_chunk)\n\n    return np.array(norm_array)","execution_count":7,"outputs":[{"output_type":"stream","text":"time: 8.23 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['cleaned_data'] = chunk_clean(data.question.values)\ndata['norm_data'] = chunk_text_normalize(data.cleaned_data.values)\ndata.head()","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eaa7c29d8d2402c974448777b9da4cb"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"249757f8e44c49358aab47802a1b7d77"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                                            question  \\\n0       I am not able to access my Bitrix24 account?   \n1  What is the job profile? Will we be able to wo...   \n2  How many workgroups will an intern be a part of?    \n3                How many workgroups should I be in?   \n4      Not able to access the LP1 page with my token   \n\n                                       response_text  \\\n0  Go to https://cloudcounselage24.bitrix24.com/ ...   \n1  Your job profile is 'Technology - Intern'; if ...   \n2  Every intern should be a part of 2 workgroups....   \n3  Every intern should be a part of 2 workgroups....   \n4  Please watch the videos shared with the invite...   \n\n                                   cleaned_data  \\\n0                    able access bitrix account   \n1  job profile able work tech chosen internship   \n2                   many workgroups intern part   \n3                               many workgroups   \n4                     able access lp page token   \n\n                                      norm_data  \n0                    able access bitrix account  \n1  job profile able work tech choose internship  \n2                   many workgroups intern part  \n3                               many workgroups  \n4                     able access lp page token  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>response_text</th>\n      <th>cleaned_data</th>\n      <th>norm_data</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am not able to access my Bitrix24 account?</td>\n      <td>Go to https://cloudcounselage24.bitrix24.com/ ...</td>\n      <td>able access bitrix account</td>\n      <td>able access bitrix account</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the job profile? Will we be able to wo...</td>\n      <td>Your job profile is 'Technology - Intern'; if ...</td>\n      <td>job profile able work tech chosen internship</td>\n      <td>job profile able work tech choose internship</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How many workgroups will an intern be a part of?</td>\n      <td>Every intern should be a part of 2 workgroups....</td>\n      <td>many workgroups intern part</td>\n      <td>many workgroups intern part</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>How many workgroups should I be in?</td>\n      <td>Every intern should be a part of 2 workgroups....</td>\n      <td>many workgroups</td>\n      <td>many workgroups</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Not able to access the LP1 page with my token</td>\n      <td>Please watch the videos shared with the invite...</td>\n      <td>able access lp page token</td>\n      <td>able access lp page token</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"stream","text":"time: 2.73 s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Vectorizing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"word_vectorizer = TfidfVectorizer()\nfaq_data = word_vectorizer.fit_transform(data.norm_data.values).toarray() ","execution_count":9,"outputs":[{"output_type":"stream","text":"time: 35 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"faq_data_features=pd.DataFrame(faq_data,columns=word_vectorizer.get_feature_names()) \nvocab_text = list(faq_data_features.columns)\nfaq_data_features.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"       able  abort  absolutely  abysmal  accept    access   account  \\\n0  0.455634    0.0         0.0      0.0     0.0  0.455634  0.555086   \n1  0.356341    0.0         0.0      0.0     0.0  0.000000  0.000000   \n2  0.000000    0.0         0.0      0.0     0.0  0.000000  0.000000   \n3  0.000000    0.0         0.0      0.0     0.0  0.000000  0.000000   \n4  0.462346    0.0         0.0      0.0     0.0  0.462346  0.000000   \n\n   acknowledgment  actually  add  ...  yap   ye  yea  yeah  year  yeh  yep  \\\n0             0.0       0.0  0.0  ...  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n1             0.0       0.0  0.0  ...  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n2             0.0       0.0  0.0  ...  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n3             0.0       0.0  0.0  ...  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n4             0.0       0.0  0.0  ...  0.0  0.0  0.0   0.0   0.0  0.0  0.0   \n\n   yes  yet  yup  \n0  0.0  0.0  0.0  \n1  0.0  0.0  0.0  \n2  0.0  0.0  0.0  \n3  0.0  0.0  0.0  \n4  0.0  0.0  0.0  \n\n[5 rows x 637 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>able</th>\n      <th>abort</th>\n      <th>absolutely</th>\n      <th>abysmal</th>\n      <th>accept</th>\n      <th>access</th>\n      <th>account</th>\n      <th>acknowledgment</th>\n      <th>actually</th>\n      <th>add</th>\n      <th>...</th>\n      <th>yap</th>\n      <th>ye</th>\n      <th>yea</th>\n      <th>yeah</th>\n      <th>year</th>\n      <th>yeh</th>\n      <th>yep</th>\n      <th>yes</th>\n      <th>yet</th>\n      <th>yup</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.455634</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.455634</td>\n      <td>0.555086</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.356341</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.462346</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.462346</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 637 columns</p>\n</div>"},"metadata":{}},{"output_type":"stream","text":"time: 25 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy = 'did not get appointment letter'\ndummy = text_normalization(clean_text(dummy))\ndummy_vect = word_vectorizer.transform([dummy]).toarray()\n\ncosine_similarity=1-pairwise_distances(faq_data_features,dummy_vect,metric='cosine')\ndata['response_text'].loc[cosine_similarity.argmax()]","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"\"If you had not attended the live induction and have registered in the pre-recorded session after 4 PM, 31st March. Then you'll get your joining letter by 30th April 2020. If you have otherwise, please a mail to hrsupport@cloudcounselage.in or ping 'Cloud Counselage HR' in Bitrix24.\""},"metadata":{}},{"output_type":"stream","text":"time: 65.7 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_answer(text):\n    text = text_normalization(clean_text(text))\n    text = word_vectorizer.transform([text]).toarray()\n\n    cosine_similarity=1-pairwise_distances(faq_data_features,text,metric='cosine')\n    if max(cosine_similarity) >= 0.20:\n        output = data['response_text'].loc[cosine_similarity.argmax()]\n    else:\n        not_known_statements = ['Once again','Try once more','Say once again','Try another way','I did not understand','I did not get that']\n        output = random.choice(not_known_statements)\n    \n    return output","execution_count":26,"outputs":[{"output_type":"stream","text":"time: 1.65 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def chat():\n    print('NATU: Welcome User, I am a chatbot assistant\\n')\n    while True:\n        text = str(input('USER: '))\n        \n        if text=='quit':\n            print('NATU: ','Bye, See you again soon','\\n')\n            break\n            \n        response = predict_answer(text)\n        print('NATU: ',response,'\\n')    ","execution_count":27,"outputs":[{"output_type":"stream","text":"time: 7.7 ms\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Testing the chatbot"},{"metadata":{"trusted":true},"cell_type":"code","source":"chat()","execution_count":25,"outputs":[{"output_type":"stream","text":"NATU: Welcome User, I am a chatbot assistant\n\nUSER: hi\nNATU:  Hey! \n\nUSER: heya\nNATU:  Howdy. \n\nUSER: jkvufgiqudgiuqw\nNATU:  Say once again \n\nUSER: goudgouqfo\nNATU:  Try another way \n\nUSER: iyfiufiougigougo\nNATU:  Say once again \n\nUSER: quit\nNATU:  Bye, See you again soon \n\ntime: 2min 19s\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# THE END"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}